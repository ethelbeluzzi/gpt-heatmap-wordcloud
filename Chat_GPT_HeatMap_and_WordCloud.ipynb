{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2a305a33",
      "metadata": {
        "id": "2a305a33"
      },
      "source": [
        "\n",
        "⭐ **This script is originally by Chip Huyen and is available at:**\n",
        "\n",
        "https://github.com/chiphuyen/aie-book/blob/main/scripts/ai-heatmap.ipynb\n",
        "\n",
        "\n",
        "It was modified to work on Google Colab, to include a word cloud, and to generate the final chart combining the heat map and the word cloud, as well as minor comments.\n",
        "\n",
        "**How to use this script**\n",
        "1. Export your ChatGPT conversations. From your ChatGPT account, go to Settings -> Data controls -> Export\n",
        "2. Unzip the data export\n",
        "3. Point `convo_folder` to your exported data folder (at your Google Drive)\n",
        "4. Change `local_tz` to your local timezone so that it gets the correct timestamp of each conversation."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "aPt299O6SfGb"
      },
      "id": "aPt299O6SfGb"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytz matplotlib numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axRW1uWxSVDT",
        "outputId": "4b62d0e7-0dda-41e8-d329-0303f33be141"
      },
      "id": "axRW1uWxSVDT",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (2024.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Collecting googletrans\n",
            "  Downloading googletrans-4.0.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: httpx>=0.27.2 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.27.2->googletrans) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (0.14.0)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.27.2->googletrans)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.2.2)\n",
            "Downloading googletrans-4.0.2-py3-none-any.whl (18 kB)\n",
            "Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: hyperframe, hpack, h2, googletrans\n",
            "Successfully installed googletrans-4.0.2 h2-4.1.0 hpack-4.0.0 hyperframe-6.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pytz\n",
        "from datetime import datetime, timezone, timedelta\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n"
      ],
      "metadata": {
        "id": "njzMCJ_uSqdU"
      },
      "id": "njzMCJ_uSqdU",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accessing the File"
      ],
      "metadata": {
        "id": "jPrfZM6OSm9q"
      },
      "id": "jPrfZM6OSm9q"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyiXmzAOR3RD",
        "outputId": "aa358c68-0107-402d-ceb4-f34201a34458"
      },
      "id": "OyiXmzAOR3RD",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bef16296",
      "metadata": {
        "id": "bef16296"
      },
      "outputs": [],
      "source": [
        "convo_folder = '/content/drive/My Drive/gptdados'\n",
        "# change to where your exported ChatGPT folder is on Google Drive\n",
        "\n",
        "local_tz = 'America/Sao_Paulo' # change to your local timezone.\n",
        "# pytz.all_timezones # uncomment to see a list of all supported timezones."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating HeatMap"
      ],
      "metadata": {
        "id": "520Ik5KBSxMU"
      },
      "id": "520Ik5KBSxMU"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f7447d09",
      "metadata": {
        "id": "f7447d09"
      },
      "outputs": [],
      "source": [
        "with open(f'{convo_folder}/conversations.json', 'r') as f:\n",
        "    convs = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b30fff71",
      "metadata": {
        "id": "b30fff71"
      },
      "outputs": [],
      "source": [
        "convo_times = []\n",
        "for conv in convs:\n",
        "    # Given Unix timestamp\n",
        "    unix_timestamp = conv['create_time']\n",
        "\n",
        "    # Convert to UTC datetime\n",
        "    utc_datetime = datetime.fromtimestamp(unix_timestamp, tz=timezone.utc)\n",
        "\n",
        "    # Convert UTC datetime to local timezone\n",
        "    pt_datetime = utc_datetime.astimezone(pytz.timezone(local_tz))\n",
        "    convo_times.append(pt_datetime)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0c121446",
      "metadata": {
        "id": "0c121446"
      },
      "outputs": [],
      "source": [
        "def create_year_heatmap(convo_times, year):\n",
        "    # Convert convo_times to dates and filter for the given year\n",
        "    just_dates = [convo.date() for convo in convo_times if convo.year == year]\n",
        "\n",
        "    date_counts = Counter(just_dates)\n",
        "\n",
        "    # Create a full year date range for the calendar\n",
        "    start_date = datetime(year, 1, 1).date()\n",
        "    end_date = datetime(year, 12, 31).date()\n",
        "\n",
        "    total_days = (end_date - start_date).days + 1\n",
        "    date_range = [start_date + timedelta(days=i) for i in range(total_days)]\n",
        "\n",
        "    # Prepare data for plotting\n",
        "    data = []\n",
        "    for date in date_range:\n",
        "        week = ((date - start_date).days + start_date.weekday()) // 7\n",
        "        day_of_week = date.weekday()\n",
        "        count = date_counts.get(date, 0)\n",
        "        data.append((week, day_of_week, count))\n",
        "\n",
        "    weeks_in_year = (end_date - start_date).days // 7 + 1\n",
        "\n",
        "    # Plot the heatmap\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    ax = plt.gca()\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "    max_count_date = max(date_counts, key=date_counts.get)\n",
        "    max_count = date_counts[max_count_date]\n",
        "    p90_count = np.percentile(list(date_counts.values()), 90)\n",
        "    for week, day_of_week, count in data:\n",
        "        color = plt.cm.Greens((count + 1) / p90_count) if count > 0 else 'lightgray'\n",
        "        rect = patches.Rectangle((week, day_of_week), 1, 1, linewidth=0.5, edgecolor='black', facecolor=color)\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    # Replace week numbers with month names below the heatmap\n",
        "    month_starts = [start_date + timedelta(days=i) for i in range(total_days)\n",
        "                    if (start_date + timedelta(days=i)).day == 1]\n",
        "    for month_start in month_starts:\n",
        "        week = (month_start - start_date).days // 7\n",
        "        plt.text(week + 0.5, 7.75, month_start.strftime('%b'), ha='center', va='center', fontsize=10, rotation=0)\n",
        "\n",
        "    # Adjustments for readability\n",
        "    ax.set_xlim(-0.5, weeks_in_year + 0.5)\n",
        "    ax.set_ylim(-0.5, 8.5)\n",
        "    plt.title(\n",
        "        f'{year} ChatGPT Conversation Heatmap (total={sum(date_counts.values())}).\\nMost active day: {max_count_date} with {max_count} convos.',\n",
        "        fontsize=16\n",
        "    )\n",
        "    plt.xticks([])\n",
        "    plt.yticks(range(7), ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff30f0cf",
      "metadata": {
        "id": "ff30f0cf"
      },
      "outputs": [],
      "source": [
        "create_year_heatmap(convo_times, 2025)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a6bcaae",
      "metadata": {
        "id": "5a6bcaae"
      },
      "outputs": [],
      "source": [
        "create_year_heatmap(convo_times, 2024)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating WordCloud"
      ],
      "metadata": {
        "id": "wtP9QbeumpT4"
      },
      "id": "wtP9QbeumpT4"
    },
    {
      "cell_type": "code",
      "source": [
        "titles = []\n",
        "for conv in convs:\n",
        "    titles.append(conv['title'])"
      ],
      "metadata": {
        "id": "0NncOuMrUUc1"
      },
      "id": "0NncOuMrUUc1",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure NLTK stopwords are downloaded\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Stopwords in English and Portuguese (works for both)\n",
        "english_stopwords = set(stopwords.words('english'))\n",
        "portuguese_stopwords = set(stopwords.words('portuguese'))\n",
        "\n",
        "# Combine stopwords from both languages\n",
        "all_stopwords = english_stopwords.union(portuguese_stopwords)\n",
        "\n",
        "# Join all titles into a single string\n",
        "text = \" \".join(titles)\n",
        "\n",
        "# Generate the word cloud\n",
        "wordcloud = WordCloud(\n",
        "    width=1000,              # Adjust width\n",
        "    height=500,              # Adjust height\n",
        "    background_color='white',  # Change background\n",
        "    colormap='Blues',       # Change colormap\n",
        "    max_words=250,           # Change the number of words\n",
        "    stopwords=all_stopwords,  # Remove stopwords\n",
        "    relative_scaling=0.8,  # Adjust relative scaling\n",
        "    max_font_size=120,\n",
        "    min_font_size=20,\n",
        "    prefer_horizontal=0.75,   # Prioritize horizontal words\n",
        "    contour_width=0.5,\n",
        "    contour_color='gray'      # Adjustcontour\n",
        ").generate(text)\n",
        "\n",
        "# Plot the word cloud\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Most Common Conversations with ChatGPT\", fontsize=16, color='black')"
      ],
      "metadata": {
        "id": "z3OnATe4iVEN"
      },
      "id": "z3OnATe4iVEN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating a unique visualization of the HeatMap and WordCloud"
      ],
      "metadata": {
        "id": "oNWjJn8vrcY3"
      },
      "id": "oNWjJn8vrcY3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Stopwords in English and Portuguese\n",
        "english_stopwords = set(stopwords.words('english'))\n",
        "portuguese_stopwords = set(stopwords.words('portuguese'))\n",
        "all_stopwords = english_stopwords.union(portuguese_stopwords)\n",
        "\n",
        "# Join all titles into a single string\n",
        "text = \" \".join(titles)\n",
        "\n",
        "# Generate the word cloud\n",
        "wordcloud = WordCloud(\n",
        "    width=1000,              # Adjust width\n",
        "    height=500,              # Adjust height\n",
        "    background_color='white',  # Change background\n",
        "    colormap='Greens',       # Change colormap\n",
        "    max_words=350,           # Change the number of words\n",
        "    stopwords=all_stopwords,  # Remove stopwords\n",
        "    relative_scaling=0.85,  # Adjust relative scaling\n",
        "    max_font_size=120,\n",
        "    min_font_size=10,\n",
        "    prefer_horizontal=0.75,   # Prioritize horizontal words\n",
        "    contour_width=0.5,\n",
        "    contour_color='darkgreen'      # Adjustcontour\n",
        ").generate(text)\n",
        "\n",
        "# Function to create a heatmap\n",
        "def create_filtered_year_heatmap(convo_times, year1, year2, ax):\n",
        "    # Filter dates for year1 (all months) and year2 (only January by default)\n",
        "    # To adjust months for year2, modify the condition (e.g., convo.month <= 3 for Jan-Mar)\n",
        "    just_dates = [\n",
        "        convo.date() for convo in convo_times\n",
        "        if (convo.year == year1) or (convo.year == year2 and convo.month == 1)\n",
        "    ]\n",
        "\n",
        "    date_counts = Counter(just_dates)\n",
        "\n",
        "    start_date = datetime(year1, 1, 1).date()\n",
        "    end_date = datetime(year2, 1, 31).date()\n",
        "    total_days = (end_date - start_date).days + 1\n",
        "    date_range = [start_date + timedelta(days=i) for i in range(total_days)]\n",
        "\n",
        "    data = []\n",
        "    for date in date_range:\n",
        "        week = ((date - start_date).days + start_date.weekday()) // 7\n",
        "        day_of_week = date.weekday()\n",
        "        count = date_counts.get(date, 0)\n",
        "        data.append((week, day_of_week, count))\n",
        "\n",
        "    weeks_in_range = (end_date - start_date).days // 7 + 1\n",
        "\n",
        "    # Plot the heatmap\n",
        "    max_count_date = max(date_counts, key=date_counts.get)\n",
        "    max_count = date_counts[max_count_date]\n",
        "    p90_count = np.percentile(list(date_counts.values()), 90)\n",
        "    for week, day_of_week, count in data:\n",
        "        color = plt.cm.Greens((count + 1) / p90_count) if count > 0 else 'lightgray'\n",
        "        rect = patches.Rectangle((week, day_of_week), 1, 1, linewidth=0.5, edgecolor='black', facecolor=color)\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    # Replace week numbers with month names below the heatmap\n",
        "    month_starts = [start_date + timedelta(days=i) for i in range(total_days)\n",
        "                    if (start_date + timedelta(days=i)).day == 1]\n",
        "    for month_start in month_starts:\n",
        "        week = (month_start - start_date).days // 7\n",
        "        ax.text(week + 0.5, 7.75, month_start.strftime('%b'), ha='center', va='center', fontsize=10, rotation=0)\n",
        "\n",
        "    # Adjustments for readability\n",
        "    ax.set_xlim(-0.5, weeks_in_range + 0.5)\n",
        "    ax.set_ylim(-0.5, 8.5)\n",
        "    ax.set_title(\n",
        "        f'ChatGPT Conversation Heatmap: {year1} (all months) and {year2} (January only)\\n'\n",
        "        f'Most active day: {max_count_date} with {max_count} convos.',\n",
        "        fontsize=12\n",
        "    )\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks(range(7))\n",
        "    ax.set_yticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "\n",
        "# Create a combined visualization\n",
        "fig, axes = plt.subplots(2, 1, figsize=(14, 14))\n",
        "\n",
        "# Plot the heatmap on the first axis\n",
        "create_filtered_year_heatmap(convo_times, 2024, 2025, axes[0])\n",
        "\n",
        "# Plot the word cloud on the second axis\n",
        "axes[1].imshow(wordcloud, interpolation='bilinear')\n",
        "axes[1].axis(\"off\")\n",
        "axes[1].set_title(\n",
        "    \"Most Common Conversation Topics\",\n",
        "    fontsize=12,\n",
        "    color='black'\n",
        ")\n",
        "\n",
        "# Add a border around the word cloud\n",
        "frame_color = 'black'  # Customize the frame color\n",
        "frame_width = 2  # Customize the frame width\n",
        "axes[1].add_patch(plt.Rectangle(\n",
        "    (0, 0), 1, 1, transform=axes[1].transAxes,\n",
        "    linewidth=frame_width,\n",
        "    edgecolor=frame_color,\n",
        "    facecolor='none'\n",
        "))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BdBFjX5esRQ-"
      },
      "id": "BdBFjX5esRQ-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}